# MindFirst Engine — References and Bibliography

This page provides citations and references for factual claims and statistics used throughout the MindFirst Engine documentation.

---

## Gender Representation in AI and Data Science

### Workforce Statistics
**Claim:** Women make up only about 20% of AI and data science roles in major technology companies, and fewer than 15% at senior research level.

**References:**
1. World Economic Forum (2018). *The Global Gender Gap Report 2018*. Available at: https://www.weforum.org/reports/the-global-gender-gap-report-2018
2. Simonite, T. (2018). "AI is the future—but where are the women?" *WIRED*. Available at: https://www.wired.com/story/artificial-intelligence-researchers-gender-imbalance/
3. West, S.M., Whittaker, M., & Crawford, K. (2019). *Discriminating Systems: Gender, Race and Power in AI*. AI Now Institute. Available at: https://ainowinstitute.org/discriminatingsystems.html

### Image Dataset Representation
**Claim:** Less than 42% of the faces in the widely used ImageNet dataset were identified as female.

**References:**
1. Yang, K., Qinami, K., Fei-Fei, L., Deng, J., & Russakovsky, O. (2020). "Towards Fairer Datasets: Filtering and Balancing the Distribution of the People Subtree in the ImageNet Hierarchy." *Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (FAT* '20)*, pp. 547–558. DOI: 10.1145/3351095.3375709
2. Buolamwini, J., & Gebru, T. (2018). "Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification." *Proceedings of Machine Learning Research*, 81, pp. 1–15. Available at: http://proceedings.mlr.press/v81/buolamwini18a.html

---

## Cultural and Geographic Bias in AI Training Data

### Western Population Bias
**Claim:** Over 80% of human subject data used in fairness research is drawn from Western populations.

**References:**
1. Sap, M., Swayamdipta, S., Vianna, L., Zhou, X., Choi, Y., & Smith, N.A. (2022). "Annotators with Attitudes: How Annotator Beliefs And Identities Bias Toxic Language Detection." *Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies*, pp. 5884–5906. DOI: 10.18653/v1/2022.naacl-main.431
2. Henrich, J., Heine, S.J., & Norenzayan, A. (2010). "The weirdest people in the world?" *Behavioral and Brain Sciences*, 33(2-3), pp. 61–83. DOI: 10.1017/S0140525X0999152X
3. Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., & Galstyan, A. (2021). "A Survey on Bias and Fairness in Machine Learning." *ACM Computing Surveys*, 54(6), Article 115, pp. 1–35. DOI: 10.1145/3457607

### Cross-Cultural Performance Challenges
**Claim:** Models trained on Western contexts struggle to perform well when applied to African, Asian, or Indigenous datasets.

**References:**
1. Ogueji, K., Zhu, Y., & Lin, J. (2021). "Small Data? No Problem! Exploring the Viability of Pretrained Multilingual Language Models for Low-resourced Languages." *Proceedings of the 1st Workshop on Multilingual Representation Learning*, pp. 116–126. DOI: 10.18653/v1/2021.mrl-1.11
2. Nekoto, W., Marivate, V., Matsila, T., et al. (2020). "Participatory Research for Low-resourced Machine Translation: A Case Study in African Languages." *Findings of the Association for Computational Linguistics: EMNLP 2020*, pp. 2144–2160. DOI: 10.18653/v1/2020.findings-emnlp.195
3. Blodgett, S.L., Barocas, S., Daumé III, H., & Wallach, H. (2020). "Language (Technology) is Power: A Critical Survey of 'Bias' in NLP." *Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics*, pp. 5454–5476. DOI: 10.18653/v1/2020.acl-main.485

---

## AI Adoption and Usage Statistics

### Llama Model Downloads
**Claim:** In October 2024 alone, over two million downloads of Llama models demonstrated how quickly AI is becoming part of everyday communication.

**References:**
1. Touvron, H., et al. (2023). "Llama 2: Open Foundation and Fine-Tuned Chat Models." arXiv preprint arXiv:2307.09288. Available at: https://arxiv.org/abs/2307.09288
2. Meta AI (2024). Download and usage statistics are tracked through Hugging Face model hub: https://huggingface.co/meta-llama

**Note:** Download statistics represent publicly available metrics from model distribution platforms. Specific monthly download counts may vary based on reporting methodology.

---

## General AI Bias and Fairness Research

### Foundational Works
1. Barocas, S., & Selbst, A.D. (2016). "Big Data's Disparate Impact." *California Law Review*, 104(3), pp. 671–732. DOI: 10.15779/Z38BG31
2. Crawford, K. (2017). "The Trouble with Bias." *Keynote at NeurIPS 2017*. Video and transcript available at: https://www.youtube.com/watch?v=fMym_BKWQzk
3. Noble, S.U. (2018). *Algorithms of Oppression: How Search Engines Reinforce Racism*. NYU Press. ISBN: 978-1479837243
4. O'Neil, C. (2016). *Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy*. Crown Publishing. ISBN: 978-0553418811
5. Gebru, T., et al. (2018). "Datasheets for Datasets." arXiv preprint arXiv:1803.09010. Available at: https://arxiv.org/abs/1803.09010

### Cognitive Architecture and Personalisation
1. Mitchell, M., et al. (2019). "Model Cards for Model Reporting." *Proceedings of the Conference on Fairness, Accountability, and Transparency (FAT* '19)*, pp. 220–229. DOI: 10.1145/3287560.3287596
2. Raji, I.D., et al. (2020). "Closing the AI Accountability Gap: Defining an End-to-End Framework for Internal Algorithmic Auditing." *Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (FAT* '20)*, pp. 33–44. DOI: 10.1145/3351095.3372873

---

## Notes on References

### Citation Style
This document uses a hybrid citation style combining academic references (DOI links, arXiv identifiers) with web resources for accessibility.

### Verification and Updates
All statistics and claims should be verified against the original sources. As AI research evolves rapidly, some statistics may require periodic updates to reflect current data.

### Additional Research Areas
The MindFirst framework draws on research from multiple domains:
- Fairness in Machine Learning
- Cognitive Science and Individual Differences
- Human-Computer Interaction
- Natural Language Processing
- AI Ethics and Governance
- Privacy-Preserving Machine Learning

### Contributing References
If you identify additional relevant research or more recent statistics, please contribute updates through the standard repository contribution process.

---

**Last Updated:** December 2025  
**Version:** 1.0

[← Back to Documentation Hub](./index.md) | [← Back to Repository Root](../README.md)
